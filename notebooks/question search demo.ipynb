{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\r\n",
       "<div>\r\n",
       "    <div id='dotnet-interactive-this-cell-17932.Microsoft.DotNet.Interactive.Http.HttpPort' style='display: none'>\r\n",
       "        The below script needs to be able to find the current output cell; this is an easy method to get it.\r\n",
       "    </div>\r\n",
       "    <script type='text/javascript'>\r\n",
       "async function probeAddresses(probingAddresses) {\r\n",
       "    function timeout(ms, promise) {\r\n",
       "        return new Promise(function (resolve, reject) {\r\n",
       "            setTimeout(function () {\r\n",
       "                reject(new Error('timeout'))\r\n",
       "            }, ms)\r\n",
       "            promise.then(resolve, reject)\r\n",
       "        })\r\n",
       "    }\r\n",
       "\r\n",
       "    if (Array.isArray(probingAddresses)) {\r\n",
       "        for (let i = 0; i < probingAddresses.length; i++) {\r\n",
       "\r\n",
       "            let rootUrl = probingAddresses[i];\r\n",
       "\r\n",
       "            if (!rootUrl.endsWith('/')) {\r\n",
       "                rootUrl = `${rootUrl}/`;\r\n",
       "            }\r\n",
       "\r\n",
       "            try {\r\n",
       "                let response = await timeout(1000, fetch(`${rootUrl}discovery`, {\r\n",
       "                    method: 'POST',\r\n",
       "                    cache: 'no-cache',\r\n",
       "                    mode: 'cors',\r\n",
       "                    timeout: 1000,\r\n",
       "                    headers: {\r\n",
       "                        'Content-Type': 'text/plain'\r\n",
       "                    },\r\n",
       "                    body: probingAddresses[i]\r\n",
       "                }));\r\n",
       "\r\n",
       "                if (response.status == 200) {\r\n",
       "                    return rootUrl;\r\n",
       "                }\r\n",
       "            }\r\n",
       "            catch (e) { }\r\n",
       "        }\r\n",
       "    }\r\n",
       "}\r\n",
       "\r\n",
       "function loadDotnetInteractiveApi() {\r\n",
       "    probeAddresses([\"http://10.5.0.2:1000/\", \"http://192.168.1.4:1000/\", \"http://127.0.0.1:1000/\"])\r\n",
       "        .then((root) => {\r\n",
       "        // use probing to find host url and api resources\r\n",
       "        // load interactive helpers and language services\r\n",
       "        let dotnetInteractiveRequire = require.config({\r\n",
       "        context: '17932.Microsoft.DotNet.Interactive.Http.HttpPort',\r\n",
       "                paths:\r\n",
       "            {\r\n",
       "                'dotnet-interactive': `${root}resources`\r\n",
       "                }\r\n",
       "        }) || require;\r\n",
       "\r\n",
       "            window.dotnetInteractiveRequire = dotnetInteractiveRequire;\r\n",
       "\r\n",
       "            window.configureRequireFromExtension = function(extensionName, extensionCacheBuster) {\r\n",
       "                let paths = {};\r\n",
       "                paths[extensionName] = `${root}extensions/${extensionName}/resources/`;\r\n",
       "                \r\n",
       "                let internalRequire = require.config({\r\n",
       "                    context: extensionCacheBuster,\r\n",
       "                    paths: paths,\r\n",
       "                    urlArgs: `cacheBuster=${extensionCacheBuster}`\r\n",
       "                    }) || require;\r\n",
       "\r\n",
       "                return internalRequire\r\n",
       "            };\r\n",
       "        \r\n",
       "            dotnetInteractiveRequire([\r\n",
       "                    'dotnet-interactive/dotnet-interactive'\r\n",
       "                ],\r\n",
       "                function (dotnet) {\r\n",
       "                    dotnet.init(window);\r\n",
       "                },\r\n",
       "                function (error) {\r\n",
       "                    console.log(error);\r\n",
       "                }\r\n",
       "            );\r\n",
       "        })\r\n",
       "        .catch(error => {console.log(error);});\r\n",
       "    }\r\n",
       "\r\n",
       "// ensure `require` is available globally\r\n",
       "if ((typeof(require) !==  typeof(Function)) || (typeof(require.config) !== typeof(Function))) {\r\n",
       "    let require_script = document.createElement('script');\r\n",
       "    require_script.setAttribute('src', 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js');\r\n",
       "    require_script.setAttribute('type', 'text/javascript');\r\n",
       "    \r\n",
       "    \r\n",
       "    require_script.onload = function() {\r\n",
       "        loadDotnetInteractiveApi();\r\n",
       "    };\r\n",
       "\r\n",
       "    document.getElementsByTagName('head')[0].appendChild(require_script);\r\n",
       "}\r\n",
       "else {\r\n",
       "    loadDotnetInteractiveApi();\r\n",
       "}\r\n",
       "\r\n",
       "    </script>\r\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Installed package LemmaSharpPreBuilt-std version 1.0.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Installed package Microsoft.ML version 1.5.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Microsoft.ML\"\n",
    "#r \"nuget: LemmaSharpPreBuilt-std\"\n",
    "#r \"NeuterBot.StandardSearch.dll\"\n",
    "using Microsoft.ML;\n",
    "using Microsoft.ML.Data;\n",
    "using Microsoft.ML.Transforms.Text;\n",
    "using NeuterBot.Search;\n",
    "var mlContext = new MLContext();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Create Knowledge Base\n",
    "\n",
    "Each answer has one more questions associated with it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th>Questions</th><th>Answer</th></tr></thead><tbody><tr><td><div class=\"dni-plaintext\">[ What eats rats?, What preys on rats? ]</div></td><td><div class=\"dni-plaintext\">Cats.</div></td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th>Questions</th><th>Answer</th></tr></thead><tbody><tr><td><div class=\"dni-plaintext\">[ What do rats eat? ]</div></td><td><div class=\"dni-plaintext\">Everything.</div></td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class QnASet {\n",
    "    public IEnumerable<string> Questions {get;set;}\n",
    "    public string Answer {get;set;}\n",
    " }\n",
    "\n",
    "var qnaSet1 = new QnASet() {Questions = new [] {\"What eats rats?\", \"What preys on rats?\"},Answer = \"Cats.\"};\n",
    "var qnaSet2 = new QnASet() {Questions = new [] {\"What do rats eat?\"}, Answer = \"Everything.\"};\n",
    "display(qnaSet1);\n",
    "display(qnaSet2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't do any processing on the text of the answers - the users see that verbatim.\n",
    "We just need to track which answer corresponds to each question.\n",
    "So we'll work from now on with list of pairs of single questions and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QnaPair  {\n",
    "     public string Question {get;set;}\n",
    "    public string Answer {get;set;}\n",
    "    public string NormalisedQuestion {get;set;}\n",
    "    public string[] Tokens {get;set;}\n",
    "    public string[] TokensWithStopWordsRemoved {get;set;}\n",
    "    public string[] LemmatizedTokens {get;set;}\n",
    "    \n",
    "    public float[] TFVector {get;set;}\n",
    "    public float[] IDFVector {get;set;}\n",
    "    public float[] TFIDFVector {get;set;}\n",
    "}\n",
    "var pairs = (new [] {qnaSet1, qnaSet2}).SelectMany(qnaset => qnaset.Questions.Select(q => new QnaPair() {Question = q, Answer = qnaset.Answer}));\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " 1. Make a vocab of all ngrams in the knowledge base.\n",
    " 1. Nomalise the questions (remove punctuation and convert to lower case).\n",
    " 1. Split to tokens.\n",
    " 1. Remove stop words.\n",
    " 1. Lemmatize.\n",
    " 1. Find TF vectors.\n",
    " 1. Find IDF vectors.\n",
    " 1. Multiply both vectors to get a TIIDF vector for each question.\n",
    "    \n",
    "    ![TFIDF Formulas](idfFormula.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab:\r\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th><i>index</i></th><th>value</th></tr></thead><tbody><tr><td>0</td><td><div class=\"dni-plaintext\">eat</div></td></tr><tr><td>1</td><td><div class=\"dni-plaintext\">eat|rat</div></td></tr><tr><td>2</td><td><div class=\"dni-plaintext\">rat</div></td></tr><tr><td>3</td><td><div class=\"dni-plaintext\">prey</div></td></tr><tr><td>4</td><td><div class=\"dni-plaintext\">prey|rat</div></td></tr><tr><td>5</td><td><div class=\"dni-plaintext\">rat|eat</div></td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge Base:\r\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th><i>index</i></th><th>Question</th><th>Answer</th><th>NormalisedQuestion</th><th>Tokens</th><th>TokensWithStopWordsRemoved</th><th>LemmatizedTokens</th><th>TFVector</th><th>IDFVector</th><th>TFIDFVector</th></tr></thead><tbody><tr><td>0</td><td><div class=\"dni-plaintext\">What eats rats?</div></td><td><div class=\"dni-plaintext\">Cats.</div></td><td><div class=\"dni-plaintext\">what eats rats</div></td><td><div class=\"dni-plaintext\">[ what, eats, rats ]</div></td><td><div class=\"dni-plaintext\">[ eats, rats ]</div></td><td><div class=\"dni-plaintext\">[ eat, rat ]</div></td><td><div class=\"dni-plaintext\">[ 1, 1, 1, 0, 0, 0 ]</div></td><td><div class=\"dni-plaintext\">[ 0.4054651, 1.0986123, 0, 0, 0, 0 ]</div></td><td><div class=\"dni-plaintext\">[ 0.4054651, 1.0986123, 0, 0, 0, 0 ]</div></td></tr><tr><td>1</td><td><div class=\"dni-plaintext\">What preys on rats?</div></td><td><div class=\"dni-plaintext\">Cats.</div></td><td><div class=\"dni-plaintext\">what preys on rats</div></td><td><div class=\"dni-plaintext\">[ what, preys, on, rats ]</div></td><td><div class=\"dni-plaintext\">[ preys, rats ]</div></td><td><div class=\"dni-plaintext\">[ prey, rat ]</div></td><td><div class=\"dni-plaintext\">[ 0, 0, 1, 1, 1, 0 ]</div></td><td><div class=\"dni-plaintext\">[ 0, 0, 0, 1.0986123, 1.0986123, 0 ]</div></td><td><div class=\"dni-plaintext\">[ 0, 0, 0, 1.0986123, 1.0986123, 0 ]</div></td></tr><tr><td>2</td><td><div class=\"dni-plaintext\">What do rats eat?</div></td><td><div class=\"dni-plaintext\">Everything.</div></td><td><div class=\"dni-plaintext\">what do rats eat</div></td><td><div class=\"dni-plaintext\">[ what, do, rats, eat ]</div></td><td><div class=\"dni-plaintext\">[ rats, eat ]</div></td><td><div class=\"dni-plaintext\">[ rat, eat ]</div></td><td><div class=\"dni-plaintext\">[ 1, 0, 1, 0, 0, 1 ]</div></td><td><div class=\"dni-plaintext\">[ 0.4054651, 0, 0, 0, 0, 1.0986123 ]</div></td><td><div class=\"dni-plaintext\">[ 0.4054651, 0, 0, 0, 0, 1.0986123 ]</div></td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "(20,20): warning CS1701: Assuming assembly reference 'Microsoft.AspNetCore.Html.Abstractions, Version=2.2.0.0, Culture=neutral, PublicKeyToken=adb9793829ddae60' used by 'Microsoft.DotNet.Interactive.Formatting' matches identity 'Microsoft.AspNetCore.Html.Abstractions, Version=5.0.0.0, Culture=neutral, PublicKeyToken=adb9793829ddae60' of 'Microsoft.AspNetCore.Html.Abstractions', you may need to supply runtime policy\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "// No build-in lemmatizer in ML.Net, so we have to add our own.\n",
    "Action<QnaPair, QnaPair> customLemmatizerFunction = (x, y) =>\n",
    "{\n",
    "    var lemmatizer = new WrappedLemmatizer();\n",
    "    if (x.TokensWithStopWordsRemoved != null)\n",
    "    {\n",
    "        y.Question = x.Question;\n",
    "        y.Answer = x.Answer;\n",
    "        y.NormalisedQuestion = x.NormalisedQuestion;\n",
    "        y.Tokens = x.Tokens;\n",
    "        y.TokensWithStopWordsRemoved = x.TokensWithStopWordsRemoved;      \n",
    "        y.LemmatizedTokens = x.TokensWithStopWordsRemoved.Select(t => lemmatizer.Lemmatize(t)).ToArray();\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        y.LemmatizedTokens = null;\n",
    "    }\n",
    "};\n",
    "\n",
    "var textPipeline = mlContext.Transforms.Text.NormalizeText(\"NormalisedQuestion\", \"Question\", TextNormalizingEstimator.CaseMode.Lower, false, false, true)\n",
    "    .Append(mlContext.Transforms.Text.TokenizeIntoWords(\"Tokens\", \"NormalisedQuestion\"))\n",
    "    .Append(mlContext.Transforms.Text.RemoveDefaultStopWords(\"TokensWithStopWordsRemoved\",\"Tokens\"))\n",
    "    .Append(mlContext.Transforms.CustomMapping<QnaPair, QnaPair>(customLemmatizerFunction, \"CMContract\"))\n",
    "    .Append(mlContext.Transforms.Text.ProduceWordBags(outputColumnName:  \"TFVector\", inputColumnName: \"LemmatizedTokens\", ngramLength: 2, skipLength: 0, useAllLengths: true, maximumNgramsCount: 100000, weighting: NgramExtractingEstimator.WeightingCriteria.Tf ))\n",
    "    .Append(mlContext.Transforms.Text.ProduceWordBags(outputColumnName:  \"IDFVector\", inputColumnName: \"LemmatizedTokens\", ngramLength: 2, skipLength: 0, useAllLengths: true, maximumNgramsCount: 100000, weighting: NgramExtractingEstimator.WeightingCriteria.Idf ))\n",
    "    .Append(mlContext.Transforms.Conversion.MapValueToKey(\"LemmatizedTokensKeyed\",\"LemmatizedTokens\"))\n",
    "    \n",
    "    .Append(mlContext.Transforms.Text.ProduceNgrams(\"TFIDFVector\",\n",
    "        \"LemmatizedTokensKeyed\",\n",
    "        ngramLength: 2,\n",
    "        useAllLengths: true,\n",
    "        weighting: NgramExtractingEstimator.WeightingCriteria.TfIdf));\n",
    "\n",
    "var dataView = mlContext.Data.LoadFromEnumerable(pairs);\n",
    "var textTransformer = textPipeline.Fit(dataView); \n",
    "var transformedDataView = textTransformer.Transform(dataView);\n",
    "\n",
    "// show the vocab\n",
    "var featuresColumn = transformedDataView.Schema[\"TFIDFVector\"];\n",
    "VBuffer<ReadOnlyMemory<char>> slotNames = default;\n",
    "featuresColumn.GetSlotNames(ref slotNames);\n",
    "var slotNamesMap = slotNames.Items();\n",
    "List<string> vocab = new List<string>();\n",
    "foreach (var ngram in slotNamesMap)\n",
    "{\n",
    "    vocab.Add(ngram.Value.ToString());\n",
    "}\n",
    "\n",
    "Console.WriteLine(\"Vocab:\");\n",
    "display(vocab);\n",
    "\n",
    "Console.WriteLine(\"Knowledge Base:\");\n",
    "var enumerated = mlContext.Data.CreateEnumerable<QnaPair>(transformedDataView,false).ToList();\n",
    "display(enumerated);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Query\n",
    "\n",
    "Firstly we get the TFIDF Vector for the query, using the vocab in the knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th><i>index</i></th><th>QueryText</th><th>TFIDFVector</th></tr></thead><tbody><tr><td>0</td><td><div class=\"dni-plaintext\">What do rats eat?</div></td><td><div class=\"dni-plaintext\">[ 0.4054651, 0, 0, 0, 0, 1.0986123 ]</div></td></tr><tr><td>1</td><td><div class=\"dni-plaintext\">What do I eat?</div></td><td><div class=\"dni-plaintext\">[ 0.4054651, 0, 0, 0, 0, 0 ]</div></td></tr><tr><td>2</td><td><div class=\"dni-plaintext\">Can I have a cake?</div></td><td><div class=\"dni-plaintext\">[ 0, 0, 0, 0, 0, 0 ]</div></td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Query {\n",
    "    public string QueryText {get;set;}\n",
    "    public float[] TFIDFVector {get;set;}\n",
    "}\n",
    "\n",
    "var testQueries = new [] {\n",
    "    \"What do rats eat?\",\n",
    "    \"What do I eat?\",\n",
    "    \"Can I have a cake?\"\n",
    "}.Select(i => new Query() {QueryText = i});\n",
    "\n",
    "var predictionEngine =  mlContext.Model.CreatePredictionEngine<QnaPair,Query>(textTransformer);\n",
    "\n",
    "List<Query> predictionResults = new List<Query>();\n",
    "foreach (var q in testQueries)\n",
    "{\n",
    "    Query prediction = new Query() {QueryText = q.QueryText};\n",
    "    predictionEngine.Predict(new QnaPair() {Question = q.QueryText}, ref prediction);\n",
    "    predictionResults.Add(prediction);\n",
    "\n",
    "}\n",
    "\n",
    "display(predictionResults);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we compare the TFIDF Vector for the query to the TFIDF vectors for each question in the knowledge base.\n",
    "\n",
    "![Cosign Similarity formula](cosignSimilarityFormula.png)\n",
    "\n",
    "![Cosign Similarity diagram](cosignDiagram.png)\n",
    "\n",
    "[Source](https://towardsdatascience.com/understanding-cosine-similarity-and-its-application-fd42f585296a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th><i>index</i></th><th>Query</th><th>ComparisonScores</th></tr></thead><tbody><tr><td>0</td><td><div class=\"dni-plaintext\">What do rats eat?</div></td><td><div class=\"dni-plaintext\">[ { Question = What eats rats?, Similarity = 0.11988320132103283 }, { Question = What preys on rats?, Similarity = 0 }, { Question = What do rats eat?, Similarity = 0.9999999999999999 } ]</div></td></tr><tr><td>1</td><td><div class=\"dni-plaintext\">What do I eat?</div></td><td><div class=\"dni-plaintext\">[ { Question = What eats rats?, Similarity = 0.3462415361002097 }, { Question = What preys on rats?, Similarity = 0 }, { Question = What do rats eat?, Similarity = 0.3462415361002097 } ]</div></td></tr><tr><td>2</td><td><div class=\"dni-plaintext\">Can I have a cake?</div></td><td><div class=\"dni-plaintext\">[ { Question = What eats rats?, Similarity = 0 }, { Question = What preys on rats?, Similarity = 0 }, { Question = What do rats eat?, Similarity = 0 } ]</div></td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "double CalculateSimilarity(float[] queryVector, float[] documentVector)\n",
    "{\n",
    "    Func<float[], float> calulateDotProduct = (qv) =>\n",
    "    {\n",
    "        float dotProduct = 0;\n",
    "        for (int i = 0; i < queryVector.Count(); i++)\n",
    "        {\n",
    "            dotProduct += (qv[i] * documentVector[i]);\n",
    "        }\n",
    "        return dotProduct;\n",
    "    };\n",
    "\n",
    "    Func<float[], double> calculateMagnitude = v => {\n",
    "        return Math.Sqrt(v.Sum(f => f * f));\n",
    "    };\n",
    "    \n",
    "    var css = calulateDotProduct(queryVector) / ((calculateMagnitude(queryVector) * calculateMagnitude(documentVector)));\n",
    "    return (Double.IsNaN(css) ? 0 : css);\n",
    "}\n",
    "\n",
    "\n",
    "var comp = predictionResults.Select(query => new { \n",
    "    Query = query.QueryText,  \n",
    "    ComparisonScores = enumerated.Select(r => new {Question = r.Question, Similarity = CalculateSimilarity(r.TFIDFVector, query.TFIDFVector)})\n",
    "    });\n",
    "\n",
    "//var comparisions = predictionResults.SelectMany(i => enumerated.Select(d => new {QueryText = i.QueryText, QuestionInKB = d.Question, Similarity = CalculateSimilarity(i.TFIDFVector,d.TFIDFVector)}));\n",
    "\n",
    "display(comp);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "file_extension": ".cs",
   "mimetype": "text/x-csharp",
   "name": "C#",
   "pygments_lexer": "csharp",
   "version": "8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
